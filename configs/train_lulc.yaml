# =============================================================================
# LULC Training Configuration
# =============================================================================

# Model Configuration
model:
  architecture: unet
  encoder: resnet34
  in_channels: 10
  num_classes: 10
  features: [64, 128, 256, 512, 1024]
  attention: true
  dropout: 0.2
  multitemporal: false

# Data Configuration
data:
  train_dir: data/processed/train
  val_dir: data/processed/val
  test_dir: data/processed/test
  tile_size: 256
  batch_size: 16
  num_workers: 4
  augmentation: true
  normalize: true
  class_weights: null # null = uniform, or [w1, w2, ...]

# Training Configuration
training:
  epochs: 100
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: adamw
  scheduler: cosine
  warmup_epochs: 5
  early_stopping:
    enabled: true
    patience: 15
    min_delta: 0.001
  gradient_clip: 1.0
  mixed_precision: true
  seed: 42

# Loss Configuration
loss:
  type: combined # ce, dice, focal, combined
  ce_weight: 0.5
  dice_weight: 0.5
  focal_gamma: 2.0

# Logging
logging:
  log_every_n_steps: 10
  save_every_n_epochs: 5
  keep_n_checkpoints: 3

# MLFlow
mlflow:
  enabled: true
  experiment_name: lulc-classification
  log_model: true
  register_model: false
